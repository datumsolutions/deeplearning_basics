{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network architectures for feature extraction\n",
    "This notebook shows an example of how to extract deep features by leveraging the architecture of Deep Neural Networks. \n",
    "The dataset used is MNIST - A database of handwritten digits \n",
    "#### Dataset Description\n",
    "1. The MNIST dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, \n",
    "which means each digit occurs 6000 times in the training set and 1000 times in the testing set. (approximately). \n",
    "2. Each image is Size Normalized and Centered \n",
    "3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n",
    "4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\envs\\git_dl_experiments\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_six'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mToTensor()])\n\u001b[0;32m      3\u001b[0m \u001b[39m# Choose the training and test datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      5\u001b[0m                                    download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[0;32m      6\u001b[0m test_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mMNIST(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m                                   download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform)\n",
      "File \u001b[1;32mc:\\Users\\Paul\\anaconda3\\envs\\git_dl_experiments\\lib\\site-packages\\torchvision\\datasets\\mnist.py:91\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     85\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     download: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     90\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform\u001b[39m=\u001b[39;49mtransform, target_transform\u001b[39m=\u001b[39;49mtarget_transform)\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39m=\u001b[39m train  \u001b[39m# training set or test set\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_legacy_exist():\n",
      "File \u001b[1;32mc:\\Users\\Paul\\anaconda3\\envs\\git_dl_experiments\\lib\\site-packages\\torchvision\\datasets\\vision.py:39\u001b[0m, in \u001b[0;36mVisionDataset.__init__\u001b[1;34m(self, root, transforms, transform, target_transform)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     32\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     33\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     target_transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     _log_api_usage_once(\u001b[39mself\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(root, torch\u001b[39m.\u001b[39;49m_six\u001b[39m.\u001b[39mstring_classes):\n\u001b[0;32m     40\u001b[0m         root \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(root)\n\u001b[0;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m root\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute '_six'"
     ]
    }
   ],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Loading the train dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Loading the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_pretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_pretrained, self).__init__()\n",
    "        # linear layer (784 -> 1 hidden node)\n",
    "        self.fc1 = nn.Linear(28 * 28, 512) # First fully connected layer which takes input image 28x28 --> 784\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 10) # Last fully connected layer which outputs our 10 labels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The view function is meant to flatten the tensor (28x28 is converted to 784)  \n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # Add hidden layer, with relu activation function\n",
    "        # Relu an activation function which allows positive values to pass through the network, whereas negative values are modified to zero\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x2 = F.relu(self.fc2(x1))\n",
    "        x3 = F.relu(self.fc3(x2))\n",
    "        x4 = F.relu(self.fc4(x3))\n",
    "        output = self.fc5(x4)\n",
    "        return output, x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_pretrained(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model_pretrained = Net_pretrained()\n",
    "model_pretrained = model_pretrained.to(device) \n",
    "print(model_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(model_pretrained.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=100):\n",
    "    # First switch the module mode to model.train() so that new weights can be learned after every epoch. \n",
    "    model_pretrained.train()\n",
    "\n",
    "    # Loop through each batch of images in train set\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "       \n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Zero out the gradients from the preivous step \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (this calls the \"forward\" function within Net)\n",
    "        output, _ = model_pretrained(data)\n",
    "\n",
    "        # Compute the Loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Do backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer.step() updates the weights accordingly\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loss_vector, accuracy_vector):\n",
    "    model_pretrained.eval()                           # model.eval() here sets the PyTorch module to evaluation mode. \n",
    "                                           \n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Convert the data and target to Pytorch tensor \n",
    "\n",
    "        # Passing images/data to the model, which return the probabilites as outputs\n",
    "        output,_ = model_pretrained(data) \n",
    "\n",
    "        # calculate the loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "\n",
    "        # convert output with maximum probabilities to predicted class\n",
    "        # # get the index of the max log-probability\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        # compare predictions to true label\n",
    "        correct += (pred == target).sum().item()\n",
    "    \n",
    "    # Calculating the loss\n",
    "    test_loss /= len(test_loader)\n",
    "    loss_vector.append(test_loss)\n",
    "\n",
    "    # Calculating the accuracy\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    accuracy_vector.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    return accuracy_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298703\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.304837\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.294628\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.290450\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.290012\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.294807\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.286156\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.292574\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.271195\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.279348\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.265738\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.231220\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.235354\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.188515\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.097106\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.824871\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.745570\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.368737\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.036821\n",
      "\n",
      "Test set: Average loss: 0.9339, Accuracy: 7179/10000 (72%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.987243\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.666317\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.976047\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.709557\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.409440\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.864944\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.520378\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.590152\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.356502\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.570912\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.761089\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.548623\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.633681\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.278906\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.597863\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.238599\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.391880\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.589973\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.182401\n",
      "\n",
      "Test set: Average loss: 0.3702, Accuracy: 8877/10000 (89%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.580727\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.579096\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.234459\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.131108\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.342658\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.128225\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.361154\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.492512\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.410251\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.160577\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.371396\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.170019\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.390291\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.185294\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.175453\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.317219\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.511181\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.147321\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.336400\n",
      "\n",
      "Test set: Average loss: 0.2687, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "CPU times: total: 5min 45s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 3\n",
    "\n",
    "lossv, accv = [], []\n",
    "acc_vector = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    acc_vector = test(lossv, accv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "PATH = \"network_pretrained_layer4_512n.pt\"\n",
    "\n",
    "# Save the pytorch trained model\n",
    "torch.save(model_pretrained.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_pretrained(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc5): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained = Net_pretrained()\n",
    "model_pretrained.load_state_dict(torch.load(PATH))\n",
    "model_pretrained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git_dl_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
